{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b938d1a2-028e-428a-a39c-d1eec3211e11",
   "metadata": {},
   "source": [
    "## Calculating the costs\n",
    "\n",
    "### Total Size of the Database \n",
    "\n",
    "The total size of the database can be calculated using the following relationship:\n",
    "\n",
    "$$n_c \\times c \\geq N$$\n",
    "\n",
    "where \n",
    "\n",
    "* $N$ is the total number of characters in all documents.\n",
    "* $n_c$ is the number of chunks.\n",
    "* $c$ is the chunk size.\n",
    "\n",
    "If the overlap between chunks is zero, then: $n_c \\times c = N$\n",
    "\n",
    "In other words, if there is an overlap $v \\in (0,1) $ (a fraction of the chunk size $c$), then the total size of the database $T$ is given by:\n",
    "\n",
    "$$T=\\frac{1}{1-v} N$$\n",
    "\n",
    "For example, if we have an overlap of $v=1/3$ of overlapping (200 chunk overlap for a chunk size of 600), then the total size of the database will be 1.5 times the total number of characters in all documents: $T=1.5 \\; N$. \n",
    "\n",
    "### Convert Characters to Tokens\n",
    "\n",
    "A common rule of thumb is that one token corresponds to approximately four characters: \n",
    "\n",
    "$$N_{tokens} = N_{characters}/ 4$$\n",
    "\n",
    "The number of characters per token can actually vary, ranging from 1,500 to 3,000.\n",
    "\n",
    "\n",
    "Here's a pivot table comparing GPT-4o, GPT-4o mini, and GPT-3.5 Turbo (in dollars per millon tokens  $ $ $ per 1M tokens):\n",
    "\n",
    "| Model | Max Input Tokens (Context) | Max Output Tokens (Answer) | Input Token Cost | Output Token Cost |\n",
    "|-------|-----------------|-----------------------|--------------------|-----------------|\n",
    "| GPT-4o | 128,000 | 16,384 | 5.00 | 15.00  |\n",
    "| GPT-4o mini | 128,000 | 16,384 | 0.15 | 0.60 |\n",
    "| GPT-3.5 Turbo | 16,384 | 4,096 | 3.00 | 6.00 |\n",
    "\n",
    "\n",
    "Suppose that, on average, we send 150 tokens per request and receive 250 tokens in response. How much will it cost to run 1,000 requests?\n",
    "\n",
    "\n",
    "* Input: $0.6 \\$ $ for 1M tokens\n",
    "\n",
    "* Output: $0.15 \\$ $ for 1M tokens\n",
    "\n",
    "\n",
    "$(150\\times 0.6 \\; + \\; 250\\times0.15)\\times 10^3/10^6= 0.13 \\$ $\n",
    "\n",
    "Formula:\n",
    "\n",
    "$$(\\overline{X}\\times\\text{cost}_X \\; + \\; \\overline{Y}\\times\\text{cost}_Y)\\times \\frac{N_{req}}{N_{tokens}}= \\text{price}\\; \\$ $$\n",
    "\n",
    "* $\\overline{X}$ - average number of input tokens per request \n",
    "* $\\overline{Y}$ - average number of output tokens per request \n",
    "* $\\text{cost}_X$ - cost of an input token \n",
    "* $\\text{cost}_Y$ - cost of an output token \n",
    "* $N_{req}$ - number of requests\n",
    "* $N_{tokens}$ - number of tokens in the specified cost\n",
    "\n",
    "---\n",
    "\n",
    "from [OpenAI](https://platform.openai.com/docs/guides/embeddings/embedding-models):\n",
    "\n",
    "```python\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")\n",
    "\n",
    "```\n",
    "\n",
    "`cl100k_base` is used in gpt-4, gpt-3.5-turbo, text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large. \n",
    "\n",
    "The cost of embeddings varies depending on the size of the models: inference from larger models costs more, but larger embeddings are of higher quality.\n",
    "\n",
    "| Model                    | Dimensions | Price ($ $ $ per 1M tokens)   | Performance on MTEB Eval | Max Input (tokens) |\n",
    "|--------------------------|------------|----------------|--------------------|-----------|\n",
    "| text-embedding-3-small   |     1536     |   0.020      | 62.3%        | 8191      |\n",
    "| text-embedding-3-large   |     3072     |   0.130      | 64.6%        | 8191      |\n",
    "| text-embedding-ada-002   |     1536     |   0.100      | 61.0%        | 8191      |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce06008-0934-4518-b932-6a782b760769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_llm_cost(avg_input_tokens, avg_output_tokens, input_cost, output_cost, num_requests, tokens_per_cost):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    avg_input_tokens (float): Average number of input tokens per request\n",
    "    avg_output_tokens (float): Average number of output tokens per request\n",
    "    input_cost (float): Cost of an input token\n",
    "    output_cost (float): Cost of an output token\n",
    "    num_requests (int): Number of requests\n",
    "    tokens_per_cost (int): Number of tokens in the specified cost\n",
    "    \n",
    "    Returns:\n",
    "    float: The calculated price in dollars\n",
    "    \"\"\"\n",
    "    # Calculate the cost per request\n",
    "    cost_per_request = (avg_input_tokens * input_cost) + (avg_output_tokens * output_cost)\n",
    "    \n",
    "    # Calculate the total price\n",
    "    price = cost_per_request * (num_requests / tokens_per_cost)\n",
    "    \n",
    "    return round(price, 3)\n",
    "\n",
    "def calculate_embeddings_cost(avg_input_tokens, input_cost, num_requests, tokens_per_cost):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    avg_input_tokens (float): Average number of input tokens per request\n",
    "    input_cost (float): Cost of an input token\n",
    "    num_requests (int): Number of requests\n",
    "    tokens_per_cost (int): Number of tokens in the specified cost\n",
    "    \n",
    "    Returns:\n",
    "    float: The calculated price in dollars\n",
    "    \"\"\"\n",
    "    # Calculate the cost per request\n",
    "    cost_per_request = avg_input_tokens * input_cost\n",
    "    \n",
    "    # Calculate the total price\n",
    "    price = cost_per_request * (num_requests / tokens_per_cost)\n",
    "    \n",
    "    return round(price, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bdb2b5b-478d-4a37-a2dc-58cb5f4e59e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price LLM: 21.157$\n",
      "Price Embeddings: 0.006$\n",
      "Price Total: 21.163$\n"
     ]
    }
   ],
   "source": [
    "# in dollars \n",
    "chunk_size_char = 2000\n",
    "chunk_size = chunk_size_char/4 # in tokens\n",
    "rank_size = 5 # how many chunks are retrieved for the context\n",
    "num_chanks = 100 \n",
    "\n",
    "# 13000 students ask a single question \n",
    "avg_input_tokens = 150 # the length of a question\n",
    "avg_output_tokens = 250  # the length of a answer\n",
    "num_requests = 13000  # number of students/queries \n",
    "\n",
    "rag_input = chunk_size*rank_size + avg_input_tokens\n",
    "\n",
    "# COST OF MODELS\n",
    "input_cost = 0.6\n",
    "output_cost = 0.15\n",
    "\n",
    "#emb_cost = 0.020 # cheapest OpenAI embeddings: text-embedding-3-small\n",
    "emb_cost = 0.10 # text-embedding-ada-002\n",
    "tokens_per_cost = 1000000\n",
    "\n",
    "price_llm = calculate_llm_cost(rag_input,\n",
    "                        avg_output_tokens, \n",
    "                        input_cost, \n",
    "                        output_cost, \n",
    "                        num_requests, \n",
    "                        tokens_per_cost)\n",
    "\n",
    "rag_input_tokens = chunk_size*num_chanks\n",
    "\n",
    "# In general, we need to create embeddings 1 time, but in practice, it can be several attempts\n",
    "price_emb = calculate_embeddings_cost(rag_input_tokens,\n",
    "                                      emb_cost, 1, \n",
    "                                      tokens_per_cost)\n",
    "\n",
    "print(f\"Price LLM: {price_llm}$\")\n",
    "print(f\"Price Embeddings: {price_emb}$\")\n",
    "print(f\"Price Total: {round(price_llm+price_emb,3)}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22de07d7-df44-47c0-9cb6-5eaf3a30b3fa",
   "metadata": {},
   "source": [
    "```\n",
    "python3 RAG_calculator.py\n",
    "```\n",
    "\n",
    "\n",
    "![rag_cost](rag_cost.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458422a7-0a26-4594-a493-754a2ce6e009",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Doesnâ€™t work stable, see RAG_calculator.py\n",
    "\n",
    "# import tkinter as tk\n",
    "# from tkinter import ttk\n",
    "\n",
    "# def calculate():\n",
    "#     try:\n",
    "#         chunk_size_char = int(chunk_size_entry.get())\n",
    "#         #chunk_size_char = 2000\n",
    "#         chunk_size = chunk_size_char / 4  # in tokens\n",
    "        \n",
    "#         rank_size = int(rank_size_entry.get())\n",
    "#         num_chunks = int(num_chunks_entry.get())\n",
    "#         avg_input_tokens = int(avg_input_tokens_entry.get())\n",
    "#         avg_output_tokens = int(avg_output_tokens_entry.get())\n",
    "#         num_requests = int(num_requests_entry.get())\n",
    "\n",
    "#         rag_input = chunk_size * rank_size + avg_input_tokens\n",
    "\n",
    "#         # COST OF MODELS\n",
    "#         input_cost = 0.6\n",
    "#         output_cost = 0.15\n",
    "#         emb_cost = 0.020\n",
    "#         tokens_per_cost = 1000000\n",
    "\n",
    "#         price_llm = calculate_llm_cost(rag_input, avg_output_tokens, input_cost, output_cost, num_requests, tokens_per_cost)\n",
    "\n",
    "#         rag_input_tokens = chunk_size * num_chunks\n",
    "\n",
    "#         price_emb = calculate_embeddings_cost(rag_input_tokens, emb_cost, 1, tokens_per_cost)\n",
    "\n",
    "#         price_total = round(price_llm + price_emb, 3)\n",
    "\n",
    "#         result_label.config(text=f\"Price LLM: ${price_llm}\\nPrice Embeddings: ${price_emb}\\nPrice Total: ${price_total}\")\n",
    "#     except ValueError:\n",
    "#         result_label.config(text=\"Please enter valid numbers\")\n",
    "\n",
    "# # Create the main window\n",
    "# root = tk.Tk()\n",
    "# root.title(\"RAG Calculator\")\n",
    "\n",
    "# # Create and place input fields\n",
    "# ttk.Label(root, text=\"Chunk Size:\").grid(row=0, column=0, padx=5, pady=5)\n",
    "# chunk_size_entry = ttk.Entry(root)\n",
    "# chunk_size_entry.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "# ttk.Label(root, text=\"Rank Size:\").grid(row=1, column=0, padx=5, pady=5)\n",
    "# rank_size_entry = ttk.Entry(root)\n",
    "# rank_size_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "# ttk.Label(root, text=\"Number of Chunks:\").grid(row=2, column=0, padx=5, pady=5)\n",
    "# num_chunks_entry = ttk.Entry(root)\n",
    "# num_chunks_entry.grid(row=2, column=1, padx=5, pady=5)\n",
    "\n",
    "# ttk.Label(root, text=\"Avg Input Tokens:\").grid(row=3, column=0, padx=5, pady=5)\n",
    "# avg_input_tokens_entry = ttk.Entry(root)\n",
    "# avg_input_tokens_entry.grid(row=3, column=1, padx=5, pady=5)\n",
    "\n",
    "# ttk.Label(root, text=\"Avg Output Tokens:\").grid(row=4, column=0, padx=5, pady=5)\n",
    "# avg_output_tokens_entry = ttk.Entry(root)\n",
    "# avg_output_tokens_entry.grid(row=4, column=1, padx=5, pady=5)\n",
    "\n",
    "# ttk.Label(root, text=\"Number of Requests:\").grid(row=5, column=0, padx=5, pady=5)\n",
    "# num_requests_entry = ttk.Entry(root)\n",
    "# num_requests_entry.grid(row=5, column=1, padx=5, pady=5)\n",
    "\n",
    "# # Create and place the calculate button\n",
    "# calculate_button = ttk.Button(root, text=\"Calculate\", command=calculate)\n",
    "# calculate_button.grid(row=6, column=0, columnspan=2, pady=10)\n",
    "\n",
    "# # Create and place the result label\n",
    "# result_label = ttk.Label(root, text=\"\")\n",
    "# result_label.grid(row=7, column=0, columnspan=2, pady=5)\n",
    "\n",
    "# # Start the main event loop\n",
    "# root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb138b-1cc6-49a6-a864-8bd69d610909",
   "metadata": {},
   "source": [
    "---\n",
    "* Author: Anastasiia Popova\n",
    "* Email: anastasiia.popova@stud.unibas.ch\n",
    "\n",
    "[Perplexity AI](https://www.perplexity.ai/) assisted in code writing, editing, and more effective information searches. The generated output underwent critical evaluation. The author is solely responsible for the content.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_v2",
   "language": "python",
   "name": "rag_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
